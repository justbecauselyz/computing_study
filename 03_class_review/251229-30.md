# RAG (Retrieval Augmented Generation)
## 1. Overview
- 거대언어모델(LLM)의 출력을 최적화하기 위해 신뢰할 수 있는 외부 지식 베이스(Knowledge Base)에서 관련 데이터를 검색하고, 이를 생성 모델의 입력값으로 활용하는 하이브리드 인공지는 프레임워크
- 기존 LLM이 가진 한계점(최신 정보 부재, 환각 현상 등)을 극복하고, 답변의 정확성과 신뢰성을 높이기 위해 고안됨

## 2. 도입 배경 및 필요성
- 범용 LLM은 사전 학습된 데이터에만 의존하므로 다음과 같은 구조적 한계가 존재
    - 최신 정보의 부재
    - Hallucination
    - 도메인 특화 지식 부족

## 3. 작동 원리
- **검색(Retrieval), 증강(Augmented), 생성(Generation)의 3단계로 구성됨**
1. 질문 입력 (User Query) - 사용자가 질문 입력
2. 정보 검색 (Retrieval)
    - 사용자의 질문을 벡터(Vector) 형태로 변환(Embedding)
    - 벡터 데이터베이스(Vector DB)에서 질문과 의미적으로 가장 유사한 문서 검색
3. 프롬프트 증강 (Context Augmentation)
    - 검색된 관련 문서를 '참고 문맥(Contet)'으로서 사용자의 원래 질문과 결합
    - ex) "다음 [문맥]을 바탕으로 [질문]에 답하시오." 형태의 프롬프트 구성.
4. 답변 생성 (Generation)
    - LLM이 증강된 프롬프트를 바탕으로 사실에 근거한 답변을 생성하여 사용자에게 제공

## 4. 핵심 구성 요소
**Embedding Model**
- 텍스트 데이터를 기계가 이해할 수 있는 숫자 벡터로 변환하는 모델
- 대표 기술/도구: OpenAI Embeddings, HuggingFace  

**Vector DB**
- 임베딩된 벡터 데이터를 저장하고, 유사도 검색(Similarity Search)를 수행하는 저장소
- 대표 기술/도구: Pincone, ChromaDB, FAISS

**LLM**
- 검색된 정보를 종합하여 최종 자연어 답변을 생성하는 언어 모델
- 대표 기술/도구: GPT-4, Gemini, Claude, Llama

**Orchestrator**
- 검색과 생성 과정을 연결하고 흐름을 제어하는 프레임워크
- 대표 기술/도구: LangChain, Llamaindex

# 아모레퍼시픽 공모전
## 설치파일
```
pip install faiss-cpu langchain-google-genai
```